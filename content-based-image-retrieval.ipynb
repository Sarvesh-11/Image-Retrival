{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-06T08:01:02.861132Z","iopub.status.busy":"2022-06-06T08:01:02.860619Z","iopub.status.idle":"2022-06-06T08:01:15.74334Z","shell.execute_reply":"2022-06-06T08:01:15.742371Z","shell.execute_reply.started":"2022-06-06T08:01:02.861039Z"},"trusted":true},"outputs":[],"source":["# Additional Dependencies\n","!pip install barbar torchsummary"]},{"cell_type":"markdown","metadata":{},"source":["# Content Based Image Retrieval (CBIR)\n","## Approach:\n","\n","- By observing the data its pretty clear that an Unsupervised alongwith couple of different Hashing approachs will be the most commendable. Although there are number of techniques in that area as well, we'll focus on Hashing and Auto-Encoder techniques:\n","    \n","    - ***Latent Feature Extraction***: In this technique we can find feature vectors for every image by creating hooks on a pre-trained network and extracting the vector from previous layers. Other technique devises the use of **AutoEncoders** where the Latent features can be extracted from Encoder itself. For the sake of this data we'll proceed with AutoEncoders. For the retrieval part we'll look into Euclidean based Search (O(NlogN)) and Hashing Based Approaches (O(logN)).\n","    <br>\n","    - ***Image Hashing Search***: This can be done by:\n","        - Uniquely quantify the contents of an image using only a single integer.\n","        - Find duplicate or near-duplicate images in a dataset of images based on their computed hashes.<br>\n","        <br>"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-06-06T08:01:15.747119Z","iopub.status.busy":"2022-06-06T08:01:15.746799Z","iopub.status.idle":"2022-06-06T08:01:18.792598Z","shell.execute_reply":"2022-06-06T08:01:18.791722Z","shell.execute_reply.started":"2022-06-06T08:01:15.747089Z"},"trusted":true},"outputs":[],"source":["import time\n","import copy\n","import pickle\n","from barbar import Bar\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import scipy\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from PIL import Image\n","import cv2\n","%matplotlib inline\n","\n","import torch\n","import torchvision\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torch.utils.data.dataset import Dataset\n","from torchvision import transforms\n","from bokeh.charts import Bar\n","from torchsummary import summary\n","\n","from tqdm import tqdm\n","from pathlib import Path\n","import gc\n","RANDOMSTATE = 0\n","\n","import os\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2022-06-06T08:01:18.796251Z","iopub.status.busy":"2022-06-06T08:01:18.79545Z","iopub.status.idle":"2022-06-06T08:01:18.853904Z","shell.execute_reply":"2022-06-06T08:01:18.852981Z","shell.execute_reply.started":"2022-06-06T08:01:18.796212Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-06T08:01:18.858103Z","iopub.status.busy":"2022-06-06T08:01:18.857745Z","iopub.status.idle":"2022-06-06T08:01:19.986629Z","shell.execute_reply":"2022-06-06T08:01:19.985569Z","shell.execute_reply.started":"2022-06-06T08:01:18.858074Z"},"trusted":true},"outputs":[],"source":["datasetPath = Path('../input/cbir-dataset2/dataset')\n","df = pd.DataFrame()\n","\n","df['image'] = [f for f in os.listdir(datasetPath) if os.path.isfile(os.path.join(datasetPath, f))]\n","df['image'] = '../input/cbir-dataset2/dataset/' + df['image'].astype(str)\n","\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Data Preparation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-06T08:01:19.988769Z","iopub.status.busy":"2022-06-06T08:01:19.987918Z","iopub.status.idle":"2022-06-06T08:01:19.996401Z","shell.execute_reply":"2022-06-06T08:01:19.995537Z","shell.execute_reply.started":"2022-06-06T08:01:19.988729Z"},"trusted":true},"outputs":[],"source":["class CBIRDataset(Dataset):\n","    def __init__(self, dataFrame):\n","        self.dataFrame = dataFrame\n","        \n","        self.transformations = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","        ])\n","    \n","    def __getitem__(self, key):\n","        if isinstance(key, slice):\n","            raise NotImplementedError('slicing is not supported')\n","        \n","        row = self.dataFrame.iloc[key]\n","        image = self.transformations(Image.open(row['image']))\n","        return image\n","    \n","    def __len__(self):\n","        return len(self.dataFrame.index)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-06T08:01:19.998536Z","iopub.status.busy":"2022-06-06T08:01:19.997758Z","iopub.status.idle":"2022-06-06T08:01:20.010343Z","shell.execute_reply":"2022-06-06T08:01:20.009332Z","shell.execute_reply.started":"2022-06-06T08:01:19.998485Z"},"trusted":true},"outputs":[],"source":["def prepare_data(DF):\n","    trainDF, validateDF = train_test_split(DF, test_size=0.05, random_state=RANDOMSTATE)\n","    train_set = CBIRDataset(trainDF)\n","    validate_set = CBIRDataset(validateDF)\n","    \n","    return train_set, validate_set"]},{"cell_type":"markdown","metadata":{},"source":["# AutoEncoder Model"]},{"cell_type":"markdown","metadata":{},"source":["![](https://hackernoon.com/hn-images/1*op0VO_QK4vMtCnXtmigDhA.png)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class ConvAutoencoder(nn.Module):\n","    def __init__(self):\n","        super(ConvAutoencoder, self).__init__()\n","        \n","        self.encoder = nn.Sequential(# in- (N,3,512,512)\n","            \n","            nn.Conv2d(in_channels=3, \n","                      out_channels=64, \n","                      kernel_size=(3,3), \n","                      stride=1, \n","                      padding=1),\n","            nn.ReLU(True),\n","            nn.Conv2d(in_channels=64, \n","                      out_channels=64, \n","                      kernel_size=(3,3), \n","                      stride=1, \n","                      padding=1),\n","            nn.ReLU(True),\n","            nn.MaxPool2d(2, stride=2), \n","            \n","            nn.Conv2d(in_channels=64, \n","                      out_channels=128, \n","                      kernel_size=(3,3), \n","                      stride=2, \n","                      padding=1),\n","            nn.ReLU(True),\n","            nn.Conv2d(in_channels=128, \n","                      out_channels=128, \n","                      kernel_size=(3,3), \n","                      stride=1, \n","                      padding=0), \n","            nn.ReLU(True),\n","            nn.MaxPool2d(2, stride=2), \n","            \n","            nn.Conv2d(in_channels=128, \n","                      out_channels=256, \n","                      kernel_size=(3,3), \n","                      stride=2, \n","                      padding=1), \n","            nn.ReLU(True),\n","            nn.Conv2d(in_channels=256, \n","                      out_channels=256, \n","                      kernel_size=(3,3), \n","                      stride=1, \n","                      padding=1), \n","            nn.ReLU(True),\n","            nn.Conv2d(in_channels=256, \n","                      out_channels=256, \n","                      kernel_size=(3,3), \n","                      stride=1, \n","                      padding=1), \n","            nn.ReLU(True),\n","            nn.MaxPool2d(2, stride=2) \n","        )\n","        self.decoder = nn.Sequential(\n","            \n","            nn.ConvTranspose2d(in_channels = 256, \n","                               out_channels=256, \n","                               kernel_size=(3,3), \n","                               stride=1,\n","                              padding=1), \n"," \n","            nn.ConvTranspose2d(in_channels=256, \n","                               out_channels=256, \n","                               kernel_size=(3,3), \n","                               stride=1, \n","                               padding=1),  \n","            nn.ReLU(True),\n","\n","            nn.ConvTranspose2d(in_channels=256, \n","                               out_channels=128, \n","                               kernel_size=(3,3), \n","                               stride=2, \n","                               padding=0),  \n","            \n","            nn.ConvTranspose2d(in_channels=128, \n","                               out_channels=64, \n","                               kernel_size=(3,3), \n","                               stride=2, \n","                               padding=1),  \n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(in_channels=64, \n","                               out_channels=32, \n","                               kernel_size=(3,3), \n","                               stride=2, \n","                               padding=1), \n","            \n","            nn.ConvTranspose2d(in_channels=32, \n","                               out_channels=32, \n","                               kernel_size=(3,3), \n","                               stride=2, \n","                               padding=1),  \n","            nn.ReLU(True),\n","            \n","            nn.ConvTranspose2d(in_channels=32, \n","                               out_channels=3, \n","                               kernel_size=(4,4), \n","                               stride=2, \n","                               padding=2),  \n","            nn.Tanh()\n","        )\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.4 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"dcda1772642fc43ae63003bbd279acfea068d71f2b8ee3a349be1704f53287ff"}}},"nbformat":4,"nbformat_minor":4}
